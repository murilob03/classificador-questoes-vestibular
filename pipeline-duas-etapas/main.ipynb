{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56656dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a22a30",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c152595",
   "metadata": {},
   "source": [
    "## Etapa I (Bert -> Matéria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murilob/codes/tcc/tcc-murilo/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5445' max='10890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5445/10890 31:03 < 31:04, 2.92 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-precision</th>\n",
       "      <th>Macro-recall</th>\n",
       "      <th>Macro-f1</th>\n",
       "      <th>Weighted-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.457100</td>\n",
       "      <td>0.416449</td>\n",
       "      <td>0.881259</td>\n",
       "      <td>0.834534</td>\n",
       "      <td>0.831361</td>\n",
       "      <td>0.828828</td>\n",
       "      <td>0.880699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.383400</td>\n",
       "      <td>0.406829</td>\n",
       "      <td>0.899403</td>\n",
       "      <td>0.847582</td>\n",
       "      <td>0.860904</td>\n",
       "      <td>0.853000</td>\n",
       "      <td>0.900280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.490961</td>\n",
       "      <td>0.897336</td>\n",
       "      <td>0.849825</td>\n",
       "      <td>0.835965</td>\n",
       "      <td>0.841553</td>\n",
       "      <td>0.896961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.515963</td>\n",
       "      <td>0.903767</td>\n",
       "      <td>0.870070</td>\n",
       "      <td>0.835652</td>\n",
       "      <td>0.848262</td>\n",
       "      <td>0.901156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.535155</td>\n",
       "      <td>0.903537</td>\n",
       "      <td>0.850867</td>\n",
       "      <td>0.864284</td>\n",
       "      <td>0.856696</td>\n",
       "      <td>0.903799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='182' max='182' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [182/182 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.5351553559303284\n",
      "eval_accuracy: 0.9035369774919614\n",
      "eval_macro-precision: 0.8508674107792381\n",
      "eval_macro-recall: 0.8642840751060729\n",
      "eval_macro-f1: 0.8566960360163511\n",
      "eval_weighted-f1: 0.9037991243161487\n",
      "eval_runtime: 34.5712\n",
      "eval_samples_per_second: 125.943\n",
      "eval_steps_per_second: 5.265\n",
      "epoch: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8712' max='10890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8712/10890 48:38 < 12:09, 2.98 it/s, Epoch 8/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-precision</th>\n",
       "      <th>Macro-recall</th>\n",
       "      <th>Macro-f1</th>\n",
       "      <th>Weighted-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>0.445913</td>\n",
       "      <td>0.882637</td>\n",
       "      <td>0.825764</td>\n",
       "      <td>0.830311</td>\n",
       "      <td>0.821135</td>\n",
       "      <td>0.884236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.400065</td>\n",
       "      <td>0.901011</td>\n",
       "      <td>0.860869</td>\n",
       "      <td>0.819026</td>\n",
       "      <td>0.829589</td>\n",
       "      <td>0.897308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.280100</td>\n",
       "      <td>0.385713</td>\n",
       "      <td>0.914102</td>\n",
       "      <td>0.868376</td>\n",
       "      <td>0.869521</td>\n",
       "      <td>0.867951</td>\n",
       "      <td>0.914702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.264100</td>\n",
       "      <td>0.462960</td>\n",
       "      <td>0.907901</td>\n",
       "      <td>0.853693</td>\n",
       "      <td>0.870202</td>\n",
       "      <td>0.860574</td>\n",
       "      <td>0.909059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.498715</td>\n",
       "      <td>0.918466</td>\n",
       "      <td>0.877205</td>\n",
       "      <td>0.872349</td>\n",
       "      <td>0.874045</td>\n",
       "      <td>0.918695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.528080</td>\n",
       "      <td>0.908130</td>\n",
       "      <td>0.861610</td>\n",
       "      <td>0.859343</td>\n",
       "      <td>0.856836</td>\n",
       "      <td>0.908628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.540322</td>\n",
       "      <td>0.914561</td>\n",
       "      <td>0.871257</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.869657</td>\n",
       "      <td>0.914736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.550821</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.877455</td>\n",
       "      <td>0.849887</td>\n",
       "      <td>0.861296</td>\n",
       "      <td>0.915232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='182' max='182' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [182/182 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.49871519207954407\n",
      "eval_accuracy: 0.9184657785943959\n",
      "eval_macro-precision: 0.8772050782796538\n",
      "eval_macro-recall: 0.8723488670329181\n",
      "eval_macro-f1: 0.8740451324078595\n",
      "eval_weighted-f1: 0.9186945698805227\n",
      "eval_runtime: 34.6397\n",
      "eval_samples_per_second: 125.694\n",
      "eval_steps_per_second: 5.254\n",
      "epoch: 8.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "\n",
    "class QuestoesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = torch.tensor(df[\"input_ids\"].tolist())\n",
    "        self.attention_mask = torch.tensor(df[\"attention_mask\"].tolist())\n",
    "        self.labels = torch.tensor(df[\"label\"].tolist())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx],\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "for FOLD in [3, 4]:\n",
    "    train_df = pd.read_parquet(f\"../data/estrato/train_fold_{FOLD}.parquet\", engine=\"fastparquet\")\n",
    "    test_df = pd.read_parquet(f\"../data/estrato/test_fold_{FOLD}.parquet\", engine=\"fastparquet\")\n",
    "    train_df[\"label\"] = train_df[\"materia\"].astype(\"category\").cat.codes\n",
    "    test_df[\"label\"] = test_df[\"materia\"].astype(\"category\").cat.codes\n",
    "\n",
    "    label2id = {\n",
    "        v: k\n",
    "        for k, v in dict(\n",
    "            enumerate(train_df[\"materia\"].astype(\"category\").cat.categories)\n",
    "        ).items()\n",
    "    }\n",
    "    id2label = dict(enumerate(train_df[\"materia\"].astype(\"category\").cat.categories))\n",
    "\n",
    "    train_dataset = QuestoesDataset(train_df)\n",
    "    test_dataset = QuestoesDataset(test_df)\n",
    "\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"neuralmind/bert-base-portuguese-cased\",\n",
    "        num_labels=len(id2label),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"./tokenizer-custom\")\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        f1_macro = f1_score(labels, predictions, average=\"macro\")\n",
    "        f1_weighted = f1_score(labels, predictions, average=\"weighted\")\n",
    "        recall = recall_score(labels, predictions, average=\"macro\", zero_division=0)\n",
    "        precision = precision_score(labels, predictions, average=\"macro\", zero_division=0)\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": acc,\n",
    "            \"macro-precision\": precision,\n",
    "            \"macro-recall\": recall,\n",
    "            \"macro-f1\": f1_macro,\n",
    "            \"weighted-f1\": f1_weighted,\n",
    "        }\n",
    "\n",
    "\n",
    "    # Cálculo dos pesos das classes\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\", classes=np.unique(train_df[\"label\"]), y=train_df[\"label\"]\n",
    "    )\n",
    "\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "\n",
    "    def weighted_ce_loss(outputs, labels, num_items_in_batch: int):\n",
    "        logits = outputs.logits\n",
    "        weight = class_weights.to(logits.device)  # type: ignore\n",
    "        return F.cross_entropy(logits, labels, weight=weight)\n",
    "\n",
    "\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_threshold=0.005, early_stopping_patience=3\n",
    "    )\n",
    "\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./modelos-treinamento\",  # Pasta para salvar o modelo\n",
    "        eval_strategy=\"epoch\",  # Avalia o modelo a cada época\n",
    "        save_strategy=\"epoch\",  # Salva o modelo a cada época\n",
    "        save_total_limit=2,  # Mantém apenas os 2 últimos modelos salvos\n",
    "        num_train_epochs=10,  # Número de épocas\n",
    "        per_device_train_batch_size=12,  # Tamanho do batch de treino. Diminua se tiver erro de memória (ex: 4)\n",
    "        per_device_eval_batch_size=24,  # Tamanho do batch de avaliação\n",
    "        warmup_ratio=0.1,  # Passos de aquecimento do otimizador\n",
    "        weight_decay=0.01,  # Regularização\n",
    "        learning_rate=4e-5,  # Taxa de aprendizado\n",
    "        logging_dir=\"./logs\",  # Pasta para logs\n",
    "        logging_steps=100,  # Exibe o progresso a cada 100 passos\n",
    "        load_best_model_at_end=True,  # Carrega o melhor modelo no final do treino\n",
    "        metric_for_best_model=\"macro-f1\",  # Usa a macro-f1 para decidir o melhor modelo\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        compute_loss_func=weighted_ce_loss,\n",
    "        callbacks=[early_stopping_callback],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    scores = trainer.evaluate()\n",
    "\n",
    "    for score_name, score_value in scores.items():\n",
    "        print(f\"{score_name}: {score_value}\")\n",
    "\n",
    "    trainer.save_model(f\"./modelos/bert/materias_fold_{FOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330fb2cd",
   "metadata": {},
   "source": [
    "## Etapa 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754aff29",
   "metadata": {},
   "source": [
    "### Clássicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d6331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: modelos/classicos/svc_matematica_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_biologia_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_quimica_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_fisica_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_historia_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_portugues_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_literatura_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_artes_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_idiomas_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_filosofia_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_sociologia_fold_4.pkl\n",
      "Salvo: modelos/classicos/svc_geografia_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_matematica_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_biologia_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_quimica_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_fisica_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_historia_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_portugues_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_literatura_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_artes_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_idiomas_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_filosofia_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_sociologia_fold_4.pkl\n",
      "Salvo: modelos/classicos/lr_geografia_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_matematica_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_biologia_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_quimica_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_fisica_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_historia_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_portugues_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_literatura_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_artes_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_idiomas_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_filosofia_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_sociologia_fold_4.pkl\n",
      "Salvo: modelos/classicos/rf_geografia_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_matematica_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_biologia_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_quimica_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_fisica_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_historia_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_portugues_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_literatura_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_artes_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_idiomas_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_filosofia_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_sociologia_fold_4.pkl\n",
      "Salvo: modelos/classicos/nb_geografia_fold_4.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Carregando dados\n",
    "train_df = pd.read_parquet(f\"../data/estrato/train_fold_{FOLD}.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "# Dicionário de modelos\n",
    "models = {\n",
    "    \"svc\": LinearSVC(C=0.316, class_weight=\"balanced\", random_state=42),\n",
    "    \"lr\": LogisticRegression(\n",
    "        C=10.0, class_weight=\"balanced\", solver=\"lbfgs\", random_state=42, max_iter=1000\n",
    "    ),\n",
    "    \"rf\": RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        max_depth=30,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"nb\": MultinomialNB(alpha=0.01),\n",
    "}\n",
    "\n",
    "# Vetorização e seleção de features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=None,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    ")\n",
    "\n",
    "selector = SelectPercentile(chi2, percentile=30)\n",
    "\n",
    "# Pipeline base\n",
    "base_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\", vectorizer),\n",
    "        (\"chi2\", selector),\n",
    "        (\"clf\", None),\n",
    "    ]\n",
    ")\n",
    "\n",
    "materias = train_df[\"materia\"].unique()\n",
    "\n",
    "\n",
    "# Função auxiliar que treina e salva um modelo\n",
    "def treinar_e_salvar(name, model, materia):\n",
    "    x = train_df[train_df[\"materia\"] == materia][\"texto_lem\"]\n",
    "    y = train_df[train_df[\"materia\"] == materia][\"topico\"]\n",
    "\n",
    "    pipeline = base_pipeline.set_params(clf=model)\n",
    "    pipeline.fit(x, y)\n",
    "\n",
    "    filename = f\"modelos/classicos/{name}_{materia}_fold_{FOLD}.pkl\"\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(pipeline, f)\n",
    "    return filename\n",
    "\n",
    "\n",
    "# Paralelizando\n",
    "tasks = []\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    for name, model in models.items():\n",
    "        for materia in materias:\n",
    "            tasks.append(executor.submit(treinar_e_salvar, name, model, materia))\n",
    "\n",
    "    for future in tasks:\n",
    "        print(\"Salvo:\", future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6e855",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    ")\n",
    "\n",
    "# ========= CONFIGURAÇÕES ========= #\n",
    "BASE_MODEL = \"adalbertojunior/distilbert-portuguese-cased\"  # neuralmind/bert-base-portuguese-cased\n",
    "TOKENIZER_PATH = \"./tokenizer-custom\"\n",
    "OUTPUT_DIR = \"./modelos/distilbert\"\n",
    "LOG_DIR = \"./logs\"\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_TRAIN = 12\n",
    "BATCH_EVAL = 24\n",
    "WARMUP_RATIO = 0.1\n",
    "LEARNING_RATE = 3e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "EARLY_STOP_PATIENCE = 4\n",
    "EARLY_STOP_DELTA = 0.005\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for FOLD in [3, 4]:\n",
    "    print(f\"\\n\\n================ FOLD {FOLD} ================\\n\\n\")\n",
    "    for MODEL, OUTPUT_DIR in [\n",
    "        (\"adalbertojunior/distilbert-portuguese-cased\", \"./modelos/distilbert\"),\n",
    "    ]: \n",
    "        print(f\"\\n\\n================ MODEL {MODEL} ================\\n\\n\")\n",
    "        # ========= DADOS ========= #\n",
    "        train_df = pd.read_parquet(\n",
    "            f\"../data/estrato/train_fold_{FOLD}.parquet\", engine=\"fastparquet\"\n",
    "        )\n",
    "        test_df = pd.read_parquet(\n",
    "            f\"../data/estrato/test_fold_{FOLD}.parquet\", engine=\"fastparquet\"\n",
    "        )\n",
    "\n",
    "        # codifica rótulos de tópicos\n",
    "        train_df[\"label\"] = train_df[\"topico\"].astype(\"category\").cat.codes\n",
    "        test_df[\"label\"] = test_df[\"topico\"].astype(\"category\").cat.codes\n",
    "\n",
    "        materias = train_df[\"materia\"].unique()\n",
    "\n",
    "        label2id = {\n",
    "            v: k\n",
    "            for k, v in dict(\n",
    "                enumerate(train_df[\"topico\"].astype(\"category\").cat.categories)\n",
    "            ).items()\n",
    "        }\n",
    "        id2label = dict(enumerate(train_df[\"topico\"].astype(\"category\").cat.categories))\n",
    "\n",
    "        # ========= TOKENIZER ========= #\n",
    "        tokenizer = BertTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "\n",
    "        # ========= DATASET ========= #\n",
    "        class QuestoesDataset(torch.utils.data.Dataset):\n",
    "            \"\"\"Dataset simples para treino e avaliação.\"\"\"\n",
    "\n",
    "            def __init__(self, df):\n",
    "                self.input_ids = torch.tensor(\n",
    "                    df[\"input_ids\"].tolist(), dtype=torch.long\n",
    "                )\n",
    "                self.attention_mask = torch.tensor(\n",
    "                    df[\"attention_mask\"].tolist(), dtype=torch.long\n",
    "                )\n",
    "                self.labels = torch.tensor(df[\"label\"].tolist(), dtype=torch.long)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                return {\n",
    "                    \"input_ids\": self.input_ids[idx],\n",
    "                    \"attention_mask\": self.attention_mask[idx],\n",
    "                    \"labels\": self.labels[idx],\n",
    "                }\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.labels)\n",
    "\n",
    "        # ========= MÉTRICAS ========= #\n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            f1_macro = f1_score(labels, preds, average=\"macro\")\n",
    "            f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
    "            recall = recall_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "            precision = precision_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "            return {\n",
    "                \"accuracy\": acc,\n",
    "                \"macro-precision\": precision,\n",
    "                \"macro-recall\": recall,\n",
    "                \"macro-f1\": f1_macro,\n",
    "                \"weighted-f1\": f1_weighted,\n",
    "            }\n",
    "\n",
    "        # ========= CALLBACK DE EARLY STOPPING ========= #\n",
    "        early_stopping_callback = EarlyStoppingCallback(\n",
    "            early_stopping_threshold=EARLY_STOP_DELTA,\n",
    "            early_stopping_patience=EARLY_STOP_PATIENCE,\n",
    "        )\n",
    "\n",
    "        # ========= CONFIGURAÇÕES DO TREINAMENTO ========= #\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./modelos-treinamento\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            save_total_limit=2,\n",
    "            num_train_epochs=NUM_EPOCHS,\n",
    "            per_device_train_batch_size=BATCH_TRAIN,\n",
    "            per_device_eval_batch_size=BATCH_EVAL,\n",
    "            warmup_ratio=WARMUP_RATIO,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "            logging_dir=LOG_DIR,\n",
    "            logging_steps=100,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"macro-f1\",\n",
    "        )\n",
    "\n",
    "        # ========= FUNÇÃO DE TREINAMENTO ========= #\n",
    "        def treinar_e_salvar_modelo(materia: str):\n",
    "            print(f\"\\n=== Treinando modelo para a matéria: {materia} ===\")\n",
    "\n",
    "            # filtra datasets\n",
    "            train_mat = train_df[train_df[\"materia\"] == materia].copy()\n",
    "            test_mat = test_df[test_df[\"materia\"] == materia].copy()\n",
    "\n",
    "            train_mat[\"label\"] = train_mat[\"topico\"].astype(\"category\").cat.codes\n",
    "            test_mat[\"label\"] = test_mat[\"topico\"].astype(\"category\").cat.codes\n",
    "\n",
    "            label2id = {\n",
    "                v: k\n",
    "                for k, v in dict(\n",
    "                    enumerate(train_mat[\"topico\"].astype(\"category\").cat.categories)\n",
    "                ).items()\n",
    "            }\n",
    "            id2label = dict(\n",
    "                enumerate(train_mat[\"topico\"].astype(\"category\").cat.categories)\n",
    "            )\n",
    "\n",
    "            # cria datasets\n",
    "            train_dataset = QuestoesDataset(train_mat)\n",
    "            test_dataset = QuestoesDataset(test_mat)\n",
    "\n",
    "            # peso das classes específico para a matéria\n",
    "            class_weights = compute_class_weight(\n",
    "                class_weight=\"balanced\",\n",
    "                classes=np.unique(train_mat[\"label\"]),\n",
    "                y=train_mat[\"label\"],\n",
    "            )\n",
    "            class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "            def weighted_ce_loss(outputs, labels, num_items_in_batch: int):\n",
    "                \"\"\"Cross-entropy ponderada pelas frequências das classes.\"\"\"\n",
    "                logits = outputs.logits\n",
    "                weights = class_weights.to(logits.device)\n",
    "                return F.cross_entropy(logits, labels, weight=weights)\n",
    "\n",
    "            # cria modelo novo para cada matéria (sem compartilhar pesos de saída)\n",
    "            model = BertForSequenceClassification.from_pretrained(\n",
    "                BASE_MODEL,\n",
    "                num_labels=len(id2label),\n",
    "                id2label=id2label,\n",
    "                label2id=label2id,\n",
    "            )\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "            # instancia trainer\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=test_dataset,\n",
    "                compute_metrics=compute_metrics,\n",
    "                compute_loss_func=weighted_ce_loss,\n",
    "                callbacks=[early_stopping_callback],\n",
    "            )\n",
    "\n",
    "            # treino e avaliação\n",
    "            trainer.train()\n",
    "            scores = trainer.evaluate()\n",
    "            print(f\"Resultados ({materia}): {scores}\")\n",
    "\n",
    "            # salva modelo\n",
    "            save_path = os.path.join(OUTPUT_DIR, f\"{materia}_fold_{FOLD}\")\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            trainer.save_model(save_path)\n",
    "            print(f\"✅ Modelo salvo em: {save_path}\")\n",
    "\n",
    "            return save_path\n",
    "\n",
    "        # ========= LOOP DE TREINAMENTO ========= #\n",
    "        for materia in materias:\n",
    "            treinar_e_salvar_modelo(materia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbba256",
   "metadata": {},
   "source": [
    "# Inferência"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694fd676",
   "metadata": {},
   "source": [
    "## Etapa I (Bert -> Matéria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58579ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predições salvas em ./results/predictions_4.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "BATCH = 24\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CHECKPOINT_PATH = f\"./modelos/bert/materias_fold_{FOLD}\"\n",
    "\n",
    "# ======== Carregar dados ========\n",
    "test_df = pd.read_parquet(f\"../data/estrato/test_fold_{FOLD}.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "\n",
    "# ======== Dataset ========\n",
    "class QuestoesDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = torch.tensor(df[\"input_ids\"].tolist(), dtype=torch.long)\n",
    "        self.attention_mask = torch.tensor(\n",
    "            df[\"attention_mask\"].tolist(), dtype=torch.long\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "# ======== Carregar modelo ========\n",
    "def load_model(checkpoint_path: str):\n",
    "    config = AutoConfig.from_pretrained(checkpoint_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint_path, config=config\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    id2label = {int(k): v for k, v in getattr(model.config, \"id2label\", {}).items()}\n",
    "    return model, id2label\n",
    "\n",
    "\n",
    "model, id2label = load_model(CHECKPOINT_PATH)\n",
    "\n",
    "# ======== Inferência ========\n",
    "test_dataset = QuestoesDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "\n",
    "y_pred = np.array(preds)\n",
    "y_pred_labels = [id2label[p] for p in y_pred]\n",
    "\n",
    "# ======== Salvar resultados ========\n",
    "results_path = f\"./results/predictions_{FOLD}.csv\"\n",
    "if os.path.exists(results_path):\n",
    "    results_df = pd.read_csv(results_path)\n",
    "else:\n",
    "    results_df = test_df[[\"id\", \"materia\", \"topico\"]].copy()\n",
    "\n",
    "# Atualiza resultados\n",
    "results_df.loc[results_df[\"id\"].isin(test_df[\"id\"]), \"bert_materia_pred\"] = (\n",
    "    y_pred_labels\n",
    ")\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"✅ Predições salvas em {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71110c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predições salvas em ./results/predictions_diretao_1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "FOLD = 1\n",
    "BATCH = 24\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CHECKPOINT_PATH = f\"./modelos/distilbert/diretao_fold_{FOLD}\"\n",
    "\n",
    "# ======== Carregar dados ========\n",
    "test_df = pd.read_parquet(f\"../data/estrato/test_fold_{FOLD}.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "\n",
    "# ======== Dataset ========\n",
    "class QuestoesDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = torch.tensor(df[\"input_ids\"].tolist(), dtype=torch.long)\n",
    "        self.attention_mask = torch.tensor(\n",
    "            df[\"attention_mask\"].tolist(), dtype=torch.long\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "# ======== Carregar modelo ========\n",
    "def load_model(checkpoint_path: str):\n",
    "    config = AutoConfig.from_pretrained(checkpoint_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint_path, config=config\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    id2label = {int(k): v for k, v in getattr(model.config, \"id2label\", {}).items()}\n",
    "    return model, id2label\n",
    "\n",
    "\n",
    "model, id2label = load_model(CHECKPOINT_PATH)\n",
    "\n",
    "# ======== Inferência ========\n",
    "test_dataset = QuestoesDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "\n",
    "y_pred = np.array(preds)\n",
    "y_pred_labels = [id2label[p] for p in y_pred]\n",
    "\n",
    "# ======== Salvar resultados ========\n",
    "results_path = f\"./results/predictions_diretao_{FOLD}.csv\"\n",
    "if os.path.exists(results_path):\n",
    "    results_df = pd.read_csv(results_path)\n",
    "else:\n",
    "    results_df = test_df[[\"id\", \"materia\", \"topico\"]].copy()\n",
    "\n",
    "# Atualiza resultados\n",
    "results_df.loc[results_df[\"id\"].isin(test_df[\"id\"]), \"distilbert_pred\"] = (\n",
    "    y_pred_labels\n",
    ")\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"✅ Predições salvas em {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed4857",
   "metadata": {},
   "source": [
    "## Etapa II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c3bb6d",
   "metadata": {},
   "source": [
    "### Clássicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8807c692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iniciando processamento do modelo: svc ===\n",
      "=== Iniciando processamento do modelo: lr ===\n",
      "=== Iniciando processamento do modelo: rf ===\n",
      "=== Iniciando processamento do modelo: nb ===\n",
      "✓ Modelo svc finalizado.\n",
      "✓ Modelo lr finalizado.\n",
      "✓ Modelo nb finalizado.\n",
      "✓ Modelo rf finalizado.\n",
      "\n",
      "✅ Resultados salvos em: ./results/real/predictions_4.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# === Configurações ===\n",
    "ORACLE = False  # Se True, usa a matéria correta em vez da predita pelo BERT\n",
    "DATA_DIR = Path(\"./data\")\n",
    "MODEL_DIR = Path(\"./modelos/classicos\")\n",
    "RESULTS_DIR = Path(\"./results\")\n",
    "\n",
    "# === Carregando dados ===\n",
    "test_path = DATA_DIR / f\"test_fold_{FOLD}.parquet\"\n",
    "test_df = pd.read_parquet(test_path, engine=\"fastparquet\")\n",
    "\n",
    "if not ORACLE:\n",
    "    df_results = pd.read_csv(RESULTS_DIR / (\"oracle\") / f\"predictions_{FOLD}.csv\")\n",
    "    test_df[\"bert_materia_pred\"] = df_results[\"bert_materia_pred\"]\n",
    "\n",
    "# === Modelos a usar ===\n",
    "model_names = [\"svc\", \"lr\", \"rf\", \"nb\"]\n",
    "\n",
    "\n",
    "# === Função auxiliar para rodar cada modelo ===\n",
    "def run_model(\n",
    "    model_name: str,\n",
    "    fold: int,\n",
    "    model_dir: Path,\n",
    "    test_df: pd.DataFrame,\n",
    "    oracle: bool = False,\n",
    "):\n",
    "    \"\"\"Carrega os modelos especializados e gera previsões para um modelo específico.\"\"\"\n",
    "    print(f\"=== Iniciando processamento do modelo: {model_name} ===\")\n",
    "\n",
    "    # Carrega os submodelos por matéria\n",
    "    model_group = {}\n",
    "    for materia in test_df[\"materia\"].unique():\n",
    "        model_path = model_dir / f\"{model_name}_{materia}_fold_{fold}.pkl\"\n",
    "        with open(model_path, \"rb\") as f:\n",
    "            model_group[materia] = pickle.load(f)\n",
    "\n",
    "    preds = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        if oracle:\n",
    "            materia = row[\"materia\"]\n",
    "        else:\n",
    "            materia = row[\"bert_materia_pred\"]\n",
    "\n",
    "        text = row[\"texto_lem\"]\n",
    "        model = model_group[materia]\n",
    "        pred = model.predict([text])[0]\n",
    "        preds.append(pred)\n",
    "\n",
    "    print(f\"✓ Modelo {model_name} finalizado.\")\n",
    "    return model_name, preds\n",
    "\n",
    "\n",
    "# === Carregar ou inicializar DataFrame de resultados ===\n",
    "if ORACLE:\n",
    "    results_path = f\"./results/oracle/predictions_{FOLD}.csv\"\n",
    "else:\n",
    "    results_path = f\"./results/real/predictions_{FOLD}.csv\"\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    results_df = pd.read_csv(results_path)\n",
    "else:\n",
    "    results_df = test_df[[\"id\", \"materia\", \"topico\"]].copy()\n",
    "\n",
    "# === Execução paralela ===\n",
    "with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    futures = {\n",
    "        executor.submit(run_model, model_name, FOLD, MODEL_DIR, test_df): model_name\n",
    "        for model_name in model_names\n",
    "    }\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        model_name, preds = future.result()\n",
    "        results_df[f\"{model_name}_topico_pred\"] = preds\n",
    "\n",
    "# === Salvando previsões ===\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Resultados salvos em: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6007d02",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f63f97e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processando modelo Transformer: bert ===\n",
      "  - Matéria: matematica\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Matéria: biologia\n",
      "  - Matéria: quimica\n",
      "  - Matéria: fisica\n",
      "  - Matéria: historia\n",
      "  - Matéria: portugues\n",
      "  - Matéria: literatura\n",
      "  - Matéria: artes\n",
      "  - Matéria: idiomas\n",
      "  - Matéria: filosofia\n",
      "  - Matéria: sociologia\n",
      "  - Matéria: geografia\n",
      "\n",
      "=== Processando modelo Transformer: distilbert ===\n",
      "  - Matéria: matematica\n",
      "  - Matéria: biologia\n",
      "  - Matéria: quimica\n",
      "  - Matéria: fisica\n",
      "  - Matéria: historia\n",
      "  - Matéria: portugues\n",
      "  - Matéria: literatura\n",
      "  - Matéria: artes\n",
      "  - Matéria: idiomas\n",
      "  - Matéria: filosofia\n",
      "  - Matéria: sociologia\n",
      "  - Matéria: geografia\n",
      "\n",
      "✅ Previsões salvas em: ./results/real/predictions_4.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# ========= CONFIG =========\n",
    "ORACLE = False  # Se True, usa a matéria correta em vez da predita pelo BERT\n",
    "BATCH_SIZE = 24\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODELS = [\"bert\", \"distilbert\"]\n",
    "\n",
    "# ========= CARREGAR DADOS =========\n",
    "test_df = pd.read_parquet(f\"./data/test_fold_{FOLD}.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "if not ORACLE:\n",
    "    df_results = pd.read_csv(RESULTS_DIR / (\"oracle\") / f\"predictions_{FOLD}.csv\")\n",
    "    test_df[\"bert_materia_pred\"] = df_results[\"bert_materia_pred\"]\n",
    "\n",
    "# Mapeia os checkpoints\n",
    "transformer_checkpoints = {}\n",
    "for model in MODELS:\n",
    "    transformer_checkpoints[model] = {}\n",
    "    for materia in test_df[\"materia\"].unique():\n",
    "        path = f\"./modelos/{model}/{materia}_fold_{FOLD}\"\n",
    "        if not os.path.exists(path):\n",
    "            raise ValueError(f\"Checkpoint não encontrado: {path}\")\n",
    "        transformer_checkpoints[model][materia] = path\n",
    "\n",
    "# Prepara arquivo de resultados\n",
    "if ORACLE:\n",
    "    results_path = f\"./results/oracle/predictions_{FOLD}.csv\"\n",
    "else:\n",
    "    results_path = f\"./results/real/predictions_{FOLD}.csv\"\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    results_df = pd.read_csv(results_path)\n",
    "else:\n",
    "    base_cols = [\"id\", \"materia\"]\n",
    "    if \"topico\" in test_df.columns:\n",
    "        base_cols.append(\"topico\")\n",
    "    results_df = test_df[base_cols].copy()\n",
    "\n",
    "\n",
    "# ========= DATASET =========\n",
    "class QuestoesDataset(Dataset):\n",
    "    \"\"\"Dataset simples de inferência (já com padding fixo).\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = torch.tensor(df[\"input_ids\"].tolist(), dtype=torch.long)\n",
    "        self.attention_mask = torch.tensor(\n",
    "            df[\"attention_mask\"].tolist(), dtype=torch.long\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "        }\n",
    "\n",
    "\n",
    "# ========= FUNÇÕES AUXILIARES =========\n",
    "def load_model(checkpoint_path: str):\n",
    "    \"\"\"Carrega modelo e id2label do checkpoint.\"\"\"\n",
    "    config = AutoConfig.from_pretrained(checkpoint_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint_path, config=config\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    id2label = {int(k): v for k, v in getattr(model.config, \"id2label\", {}).items()}\n",
    "    return model, id2label\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_model(model, dataset: Dataset) -> np.ndarray:\n",
    "    \"\"\"Executa inferência em lote.\"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = []\n",
    "    for batch in loader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds.append(torch.argmax(logits, dim=-1).cpu().numpy())\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "\n",
    "# ========= LOOP PRINCIPAL =========\n",
    "for model_name, materia_ckpts in transformer_checkpoints.items():\n",
    "    print(f\"\\n=== Processando modelo Transformer: {model_name} ===\")\n",
    "\n",
    "    # Garante coluna para o modelo no CSV\n",
    "    if model_name not in results_df.columns:\n",
    "        results_df[f\"{model_name}_topico_pred\"] = None\n",
    "\n",
    "    materias_no_teste = test_df[\"materia\"].unique().tolist()\n",
    "\n",
    "    # Verifica se há checkpoints para todas as matérias\n",
    "    faltantes = [m for m in materias_no_teste if m not in materia_ckpts]\n",
    "    if faltantes:\n",
    "        raise ValueError(\n",
    "            f\"Faltam checkpoints para as matérias {faltantes} no modelo '{model_name}'.\"\n",
    "        )\n",
    "\n",
    "    for materia in materias_no_teste:\n",
    "        print(f\"  - Matéria: {materia}\")\n",
    "        if ORACLE:\n",
    "            df_mat = test_df[test_df[\"materia\"] == materia].copy()\n",
    "        else:\n",
    "            df_mat = test_df[test_df[\"bert_materia_pred\"] == materia].copy()\n",
    "\n",
    "        # Carrega modelo específico\n",
    "        checkpoint = materia_ckpts[materia]\n",
    "        model, id2label = load_model(checkpoint)\n",
    "\n",
    "        # Inferência\n",
    "        ds = QuestoesDataset(df_mat)\n",
    "        y_pred_ids = infer_model(model, ds)\n",
    "\n",
    "        # Converte IDs em labels (caso existam no config)\n",
    "        if id2label:\n",
    "            y_pred_labels = [id2label.get(int(i), str(int(i))) for i in y_pred_ids]\n",
    "        else:\n",
    "            y_pred_labels = y_pred_ids.tolist()\n",
    "\n",
    "        # Atualiza resultados\n",
    "        results_df.loc[\n",
    "            results_df[\"id\"].isin(df_mat[\"id\"]), f\"{model_name}_topico_pred\"\n",
    "        ] = y_pred_labels\n",
    "\n",
    "# ========= SALVAR =========\n",
    "# os.makedirs(\"./results\", exist_ok=True)\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"\\n✅ Previsões salvas em: {results_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
